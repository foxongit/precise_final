# RAG Document Processing API

A FastAPI-based backend for document upload, embedding, and intelligent querying with PII masking.

## ğŸš€ Features

- **Document Upload**: Upload PDF documents with metadata (user_id, doc_id, filename)
- **Vector Storage**: Documents are embedded and stored in ChromaDB with metadata
- **Selective Querying**: Query specific documents by providing doc_ids
- **PII Masking**: Automatic masking of sensitive information (money, percentages, etc.)
- **Query Enhancement**: AI-powered query enrichment for better retrieval
- **User Management**: Separate document spaces for different users

## ğŸ“ Project Structure

```
FinalRag/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”œâ”€â”€ documents.py   # Document upload/management endpoints
â”‚   â”‚   â”œâ”€â”€ sessions.py    # Session management endpoints
â”‚   â”‚   â””â”€â”€ query.py       # Query processing endpoints
â”‚   â”œâ”€â”€ models/            # Pydantic models
â”‚   â”‚   â””â”€â”€ schemas.py     # Request/response schemas
â”‚   â”œâ”€â”€ services/          # Business logic services
â”‚   â”‚   â”œâ”€â”€ document_service.py  # Document processing service
â”‚   â”‚   â”œâ”€â”€ session_service.py   # Session management service
â”‚   â”‚   â””â”€â”€ rag_pipeline/        # RAG processing modules
â”‚   â”‚       â”œâ”€â”€ document_manager.py  # Document embedding & storage
â”‚   â”‚       â”œâ”€â”€ retriever.py        # Document retrieval
â”‚   â”‚       â”œâ”€â”€ query_enricher.py   # Query enhancement
â”‚   â”‚       â”œâ”€â”€ pii_masker.py       # PII masking
â”‚   â”‚       â”œâ”€â”€ llm_answerer.py     # LLM response generation
â”‚   â”‚       â””â”€â”€ pipeline.py         # Main RAG orchestrator
â”‚   â”œâ”€â”€ db/                # Database configuration
â”‚   â”‚   â””â”€â”€ supabase_client.py  # Supabase client setup
â”‚   â”œâ”€â”€ core/              # Core configuration
â”‚   â”‚   â””â”€â”€ config.py      # Application settings
â”‚   â””â”€â”€ main.py            # FastAPI application entry point
â”œâ”€â”€ data/                  # Data storage
â”‚   â”œâ”€â”€ uploads/           # Uploaded documents
â”‚   â”œâ”€â”€ chroma_db/         # ChromaDB vector database
â”‚   â””â”€â”€ mappings/          # PII mapping files
â”œâ”€â”€ tests/                 # Test files
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ Dockerfile            # Docker configuration
â”œâ”€â”€ docker-compose.yml    # Docker Compose setup
â”œâ”€â”€ start_direct.bat      # Main startup script
â”œâ”€â”€ start_server.bat      # Legacy startup script
â”œâ”€â”€ app.py                # Original app (backward compatibility)
â”œâ”€â”€ .env                  # Environment variables
â”œâ”€â”€ .gitignore           # Git ignore rules
â””â”€â”€ README.md            # This file
```

## ğŸ› ï¸ Setup & Installation

### 1. Quick Start (Recommended)
```bash
# Use the main startup script
start_direct.bat
```

### 2. Docker Deployment
```bash
# Build and run with Docker Compose
docker-compose up --build
```

### 3. Manual Setup
```bash
# Install dependencies
pip install -r requirements.txt

# Start the application
py -m uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

### 4. Legacy Setup (Old Structure)
```bash
# Run the original script for backward compatibility
start_server.bat
```
pip install -r requirements.txt

# Download spaCy model
python -m spacy download en_core_web_md

# Start server
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ“¡ API Endpoints

### 1. Upload Document
```http
POST /upload-document
Content-Type: multipart/form-data

Parameters:
- file: PDF file (required)
- user_id: string (required)
- doc_id: string (optional, auto-generated if not provided)
```

**Example using curl:**
```bash
curl -X POST "http://localhost:8000/upload-document" \
  -F "file=@document.pdf" \
  -F "user_id=user123" \
  -F "doc_id=doc001"
```

### 2. Get User Documents
```http
GET /documents/{user_id}
```

**Example:**
```bash
curl "http://localhost:8000/documents/user123"
```

### 3. Query Documents
```http
POST /query
Content-Type: application/json

{
  "query": "What was the revenue growth?",
  "user_id": "user123",
  "doc_ids": ["doc001", "doc002"],
  "k": 4
}
```

**Example:**
```bash
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What was Apple revenue?",
    "user_id": "user123", 
    "doc_ids": ["doc001"],
    "k": 4
  }'
```

### 4. Delete Document
```http
DELETE /documents/{user_id}/{doc_id}
```

**Example:**
```bash
curl -X DELETE "http://localhost:8000/documents/user123/doc001"
```

### 5. Health Check
```http
GET /health
```

## ğŸ§ª Testing

Use the provided test script:
```bash
python test_api.py
```

Or visit the interactive API documentation at:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ”§ Configuration

### Environment Variables
Create a `.env` file (optional):
```
OLLAMA_HOST=localhost:11434
CHROMA_PERSIST_DIR=./chroma_db
```

### LLM Model
The system uses Ollama with `llama3:latest`. Ensure Ollama is running:
```bash
ollama serve
ollama pull llama3:latest
```

## ğŸ’¡ Usage Examples

### Python Client Example
```python
import requests

# Upload document
files = {"file": open("document.pdf", "rb")}
data = {"user_id": "user123", "doc_id": "doc001"}
response = requests.post("http://localhost:8000/upload-document", 
                        files=files, data=data)

# Query documents
query_data = {
    "query": "What is the main topic?",
    "user_id": "user123",
    "doc_ids": ["doc001"],
    "k": 4
}
response = requests.post("http://localhost:8000/query", json=query_data)
```

### JavaScript/Fetch Example
```javascript
// Upload document
const formData = new FormData();
formData.append('file', fileInput.files[0]);
formData.append('user_id', 'user123');
formData.append('doc_id', 'doc001');

fetch('http://localhost:8000/upload-document', {
    method: 'POST',
    body: formData
});

// Query documents
fetch('http://localhost:8000/query', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({
        query: 'What is the revenue?',
        user_id: 'user123',
        doc_ids: ['doc001'],
        k: 4
    })
});
```

## ğŸ”’ Features

- **Multi-user Support**: Documents are isolated by user_id
- **Metadata Tracking**: Filename, upload date, chunk count stored
- **PII Protection**: Automatic masking of sensitive data
- **Selective Retrieval**: Query only specific documents
- **Persistent Storage**: ChromaDB with disk persistence
- **Error Handling**: Comprehensive error responses

## ğŸš§ Requirements

- Python 3.8+
- Ollama with llama3:latest model
- spaCy with en_core_web_md model
- ChromaDB for vector storage

## ğŸ“ API Response Examples

### Upload Response
```json
{
  "message": "Document uploaded and processed successfully",
  "doc_id": "doc001",
  "filename": "document.pdf",
  "chunks_added": 25
}
```

### Query Response
```json
{
  "status": "success",
  "original_query": "What was the revenue?",
  "enriched_query": "revenue financial performance earnings income",
  "response": "Based on the context, revenue was [MONEY_1] in Q2...",
  "retrieved_metadata": [
    {
      "doc_id": "doc001",
      "filename": "financial_report.pdf",
      "chunk_id": "doc001_chunk_5"
    }
  ],
  "processed_docs": ["doc001"]
}
```
